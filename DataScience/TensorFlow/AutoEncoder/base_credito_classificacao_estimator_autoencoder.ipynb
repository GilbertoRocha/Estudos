{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "base_credito_classificacao_estimator_autoencoder.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GilbertoRocha/Estudos/blob/master/DataScience/TensorFlow/AutoEncoder/base_credito_classificacao_estimator_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISYkQB3aWMd2",
        "colab_type": "text"
      },
      "source": [
        "Exercicio extraido do curso \"TensorFlow: Machine Learning e Deep Learning com Python\", oferecido pelo Prof. Jones Granatyr. Link do curso: https://www.udemy.com/tensorflow-machine-learning-deep-learning-python/\n",
        "\n",
        "Adicionado comentários para melhor entendimento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAriqKLJhHD9",
        "colab_type": "code",
        "outputId": "e4e7997d-5ba2-403c-bd06-883173e691d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"gilbertorocha\",\"key\":\"4d3618c473ea67622c0399535290b8ff\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "!kaggle datasets download -d gilbertorocha/credit-data-for-tensorflow-autoencoder -p /content\n",
        "\n",
        "!unzip \\*.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "mkdir: cannot create directory ‘.kaggle’: File exists\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n",
            "Downloading credit-data-for-tensorflow-autoencoder.zip to /content\n",
            "  0% 0.00/57.7k [00:00<?, ?B/s]\n",
            "100% 57.7k/57.7k [00:00<00:00, 49.8MB/s]\n",
            "Archive:  credit-data-for-tensorflow-autoencoder.zip\n",
            "  inflating: credit_data.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plL385gvhFrW",
        "colab_type": "code",
        "outputId": "9894e94d-ef2f-48de-ad73-6f20c75a4b20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# prepara os dados para a classificação, e para o encode\n",
        "import pandas as pd\n",
        "base = pd.read_csv('credit_data.csv')\n",
        "base = base.drop('i#clientid', axis = 1)\n",
        "base = base.dropna()\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler_x = StandardScaler()\n",
        "base[['income', 'age', 'loan']] = scaler_x.fit_transform(base[['income', 'age', 'loan']])\n",
        "X = base.drop('c#default', axis = 1)\n",
        "y = base['c#default']\n",
        "X.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>income</th>\n",
              "      <th>age</th>\n",
              "      <th>loan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.453898</td>\n",
              "      <td>1.336861</td>\n",
              "      <td>1.201907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.762398</td>\n",
              "      <td>0.536639</td>\n",
              "      <td>0.695744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.836733</td>\n",
              "      <td>1.637207</td>\n",
              "      <td>1.173812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.183244</td>\n",
              "      <td>0.362998</td>\n",
              "      <td>0.544366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.509532</td>\n",
              "      <td>-1.631534</td>\n",
              "      <td>1.419754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     income       age      loan\n",
              "0  1.453898  1.336861  1.201907\n",
              "1 -0.762398  0.536639  0.695744\n",
              "2  0.836733  1.637207  1.173812\n",
              "3 -0.183244  0.362998  0.544366\n",
              "4  1.509532 -1.631534  1.419754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KUOyU1phFr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# monta a estrutura da rede\n",
        "# numero de atributos que serão \"encodados\"\n",
        "neuronios_entrada = 3\n",
        "\n",
        "# numero de atributos do \"encode\", ou seja, os atributos que vão representar as entradas\n",
        "neuronios_oculta = 2\n",
        "\n",
        "# numero de atributos de saida, precisa ser igual aos de entrada, pois o encode deve\n",
        "# sempre representar a entrada fielmente, e os neuronios de saida permitem isso\n",
        "# ficando na estrutura 3 -> 2 -> 3\n",
        "neuronios_saida = neuronios_entrada\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_LADG_wt3Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYl1V_6Jt6Pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# criação dos placeholder para receberem uma carga de atributos\n",
        "# tf.float32 = tipo da entrada, um float\n",
        "# shape = formato da entrada\n",
        "#       None = Sem tamanho definido do lote (sera definido mais tarde)\n",
        "#       neuronios_entrada = quantidade de entrada\n",
        "xph = tf.placeholder(tf.float32, shape = [None, neuronios_entrada])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL-BD1pMuhTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importa uma camada densa de rede neural, aonde todos os neuronios da camanda se conectam a todos os neuronios da proxima camada\n",
        "from tensorflow.contrib.layers import fully_connected\n",
        "\n",
        "# monta a camada oculta densa\n",
        "#   inputs = recebe o place holder contendo as entradas\n",
        "#   num_outputs = recebe a quantidade de saida dos neuronios (neste caso, a saida é o dado com encode)\n",
        "#   activation_fn = funcao de ativacao, não é passada nenhuma, pois nao é interessante aplicar em um autoencoder\n",
        "camada_oculta = fully_connected(inputs = xph, num_outputs = neuronios_oculta, activation_fn = None)\n",
        "\n",
        "# monta a camada de saida da rede (entradas ja foram encodadas, e agora volta ao estado original)\n",
        "#    inputs = recebe a camanda oculta, pois esta será a saida\n",
        "#    num_outputs = recebe o numero dos neuronios da camanda de saida\n",
        "camada_saida = fully_connected(inputs = camada_oculta, num_outputs = neuronios_saida)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGwHUwtLnP4k",
        "colab_type": "code",
        "outputId": "e948f2a0-7254-4a93-feb0-2186378914ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# cria a funcao de erro\n",
        "#    labels = são as respostas corretas, neste caso como e um autoencoder, as saidas devem ser identicas as entradas\n",
        "erro = tf.losses.mean_squared_error(labels = xph, predictions = camada_saida)\n",
        "\n",
        "# cria o otimizador\n",
        "otimizador = tf.train.AdamOptimizer(0.01)\n",
        "\n",
        "# cria a funcao de treinamento\n",
        "treinamento = otimizador.minimize(erro)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m6-OELjJmne",
        "colab_type": "code",
        "outputId": "eb8fe768-e311-438e-f12c-f729bbebb3a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for epoca in range(1000):\n",
        "    # custo = recebe o valor da funcao otimizador\n",
        "    # _ = recebe o valor do retorno da funcao treinamento, mas como ela não retorna nada, deve ser ignorado (por isso o underline)\n",
        "    # feed_dict = alimenta a sessao\n",
        "    custo, _ = sess.run([erro,treinamento], feed_dict = {xph: X})\n",
        "    if epoca % 100 ==0:\n",
        "      print('erro: ' + str(custo))\n",
        "  # recupera agora a camada oculta, que seria o encode de 2 atributos\n",
        "  x2d_encode = sess.run(camada_oculta, feed_dict = {xph: X})\n",
        "  # recupera a camada de saida, com os 3 atributos originais (deveriam ser)\n",
        "  x3d_decode = sess.run(camada_saida, feed_dict = {xph: X})"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "erro: 1.5343426\n",
            "erro: 0.66898406\n",
            "erro: 0.5721266\n",
            "erro: 0.5632155\n",
            "erro: 0.56071556\n",
            "erro: 0.56038076\n",
            "erro: 0.5602559\n",
            "erro: 0.560237\n",
            "erro: 0.5602369\n",
            "erro: 0.5602368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmcjvrtHumvl",
        "colab_type": "code",
        "outputId": "19b7a195-7e67-42c3-d083-ee7f8bd758a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x2d_encode.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1997, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuDE9nUquw4j",
        "colab_type": "code",
        "outputId": "b9a390df-d13d-4992-c517-91ff80a87652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x3d_decode.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1997, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwIDeLDYvz_L",
        "colab_type": "code",
        "outputId": "9a8c8d45-3ef2-41a8-87ee-33439ac2be70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# desescalona, para visualizar\n",
        "X2 = scaler_x.inverse_transform(X)\n",
        "X2"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.61559251e+04, 5.90170151e+01, 8.10653213e+03],\n",
              "       [3.44151540e+04, 4.81171531e+01, 6.56474502e+03],\n",
              "       [5.73171701e+04, 6.31080495e+01, 8.02095330e+03],\n",
              "       ...,\n",
              "       [4.43114493e+04, 2.80171669e+01, 5.52278669e+03],\n",
              "       [4.37560566e+04, 6.39717958e+01, 1.62272260e+03],\n",
              "       [6.94365796e+04, 5.61526170e+01, 7.37883360e+03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGZ8xwlbwRsT",
        "colab_type": "code",
        "outputId": "1a788c57-8b5e-466a-8b02-8ea903b036f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# desescalona os dados ja decodificados, para ver se o encode funcionou\n",
        "x3d_decode2 = scaler_x.inverse_transform(x3d_decode)\n",
        "x3d_decode2"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.2037574e+04, 5.8928295e+01, 9.2291807e+03],\n",
              "       [4.7633383e+04, 4.8534340e+01, 4.4454878e+03],\n",
              "       [5.8417953e+04, 6.3183090e+01, 7.6981641e+03],\n",
              "       ...,\n",
              "       [5.0208191e+04, 4.0807560e+01, 4.4454878e+03],\n",
              "       [4.5333863e+04, 6.3698540e+01, 4.4454878e+03],\n",
              "       [6.2191008e+04, 5.5931473e+01, 9.2512363e+03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwC-WSUETs6Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a0b6120-a41b-47fa-cacb-c31e520749e9"
      },
      "source": [
        "# para medir a precisao, pode-se usar o mean absolute error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mae_income = mean_absolute_error(X2[:,0], x3d_decode2[:,0])\n",
        "mae_income"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9397.151988189991"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewDQDICKUB53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b0dc38e-1e57-4c61-f615-9bc86d6c79aa"
      },
      "source": [
        "mae_age = mean_absolute_error(X2[:,1], x3d_decode2[:,1])\n",
        "mae_age"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.956022837813002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbyjykmiUHvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e77673ce-3065-4008-9ccb-223cccd84e40"
      },
      "source": [
        "mae_loan = mean_absolute_error(X2[:,2], x3d_decode2[:,2])\n",
        "mae_loan"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1802.9975616917957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osXLwgMqUYCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cria um dataframe para testar com o algoritimo de classificação\n",
        "\n",
        "X_encode = pd.DataFrame({'atributo1': x2d_encode[:, 0], 'atributo2': x2d_encode[:, 1], 'classe': y})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqrkN4yIUyWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "afdaa972-9abd-4b46-a070-ea1760559f10"
      },
      "source": [
        "X_encode.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>atributo1</th>\n",
              "      <th>atributo2</th>\n",
              "      <th>classe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.945148</td>\n",
              "      <td>3.281457</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.811342</td>\n",
              "      <td>-0.166611</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.682261</td>\n",
              "      <td>2.536032</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.343701</td>\n",
              "      <td>0.353172</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-3.744917</td>\n",
              "      <td>3.088584</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   atributo1  atributo2  classe\n",
              "0   0.945148   3.281457       0\n",
              "1   0.811342  -0.166611       0\n",
              "2   1.682261   2.536032       0\n",
              "3   0.343701   0.353172       0\n",
              "4  -3.744917   3.088584       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiaYsjLGVBz_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb924e2c-abdf-4ccc-ffa1-5b02d7a31fc8"
      },
      "source": [
        "# inicia a classificação usando a base com encode\n",
        "colunas = [tf.feature_column.numeric_column(key = column) for column in X_encode.columns]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X_encode, y, test_size = 0.3, random_state = 0)\n",
        "\n",
        "funcao_treinamento = tf.estimator.inputs.pandas_input_fn(x = X_treinamento,\n",
        "                                                        y = y_treinamento,\n",
        "                                                        batch_size = 8, \n",
        "                                                        num_epochs = None,\n",
        "                                                        shuffle = True)\n",
        "\n",
        "classificador = tf.estimator.DNNClassifier(feature_columns = colunas, hidden_units = [4, 4])\n",
        "classificador.train(input_fn = funcao_treinamento, steps = 1000)\n",
        "\n",
        "funcao_teste = tf.estimator.inputs.pandas_input_fn(x = X_teste, y = y_teste,\n",
        "                                              batch_size = 8, num_epochs = 1000,\n",
        "                                              shuffle = False)\n",
        "\n",
        "metricas_teste = classificador.evaluate(input_fn = funcao_teste, steps = 1000)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpug32xjn0\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpug32xjn0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3002563cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpug32xjn0/model.ckpt.\n",
            "INFO:tensorflow:loss = 11.478398, step = 1\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 47 vs previous value: 47. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 54 vs previous value: 54. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 56 vs previous value: 56. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 73 vs previous value: 73. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 366.371\n",
            "INFO:tensorflow:loss = 3.8151975, step = 101 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.164\n",
            "INFO:tensorflow:loss = 0.5382099, step = 201 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.593\n",
            "INFO:tensorflow:loss = 0.2579604, step = 301 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.067\n",
            "INFO:tensorflow:loss = 0.15607548, step = 401 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 467.521\n",
            "INFO:tensorflow:loss = 0.11863132, step = 501 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.241\n",
            "INFO:tensorflow:loss = 0.13985246, step = 601 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.768\n",
            "INFO:tensorflow:loss = 0.041393124, step = 701 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 471.02\n",
            "INFO:tensorflow:loss = 0.022026036, step = 801 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.878\n",
            "INFO:tensorflow:loss = 0.021968875, step = 901 (0.209 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpug32xjn0/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.022997819.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-27T15:30:08Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpug32xjn0/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [100/1000]\n",
            "INFO:tensorflow:Evaluation [200/1000]\n",
            "INFO:tensorflow:Evaluation [300/1000]\n",
            "INFO:tensorflow:Evaluation [400/1000]\n",
            "INFO:tensorflow:Evaluation [500/1000]\n",
            "INFO:tensorflow:Evaluation [600/1000]\n",
            "INFO:tensorflow:Evaluation [700/1000]\n",
            "INFO:tensorflow:Evaluation [800/1000]\n",
            "INFO:tensorflow:Evaluation [900/1000]\n",
            "INFO:tensorflow:Evaluation [1000/1000]\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-27-15:30:11\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 1.0, accuracy_baseline = 0.8635, auc = 1.0, auc_precision_recall = 1.0, average_loss = 0.0026806805, global_step = 1000, label/mean = 0.1365, loss = 0.021445444, precision = 1.0, prediction/mean = 0.13787064, recall = 1.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/tmpug32xjn0/model.ckpt-1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjzgMwKTVTY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1984b4f3-2976-4dc0-ed10-96dacaff9f60"
      },
      "source": [
        "metricas_teste"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 1.0,\n",
              " 'accuracy_baseline': 0.8635,\n",
              " 'auc': 1.0,\n",
              " 'auc_precision_recall': 1.0,\n",
              " 'average_loss': 0.0026806805,\n",
              " 'global_step': 1000,\n",
              " 'label/mean': 0.1365,\n",
              " 'loss': 0.021445444,\n",
              " 'precision': 1.0,\n",
              " 'prediction/mean': 0.13787064,\n",
              " 'recall': 1.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}